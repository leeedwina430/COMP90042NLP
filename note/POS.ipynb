{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Part of Speech (POS)\n",
    "AKA word classes, morphological classes, syntactic categories; Nouns, verbs, adjective, etc\n",
    "\n",
    "POS tells us quite a bit about a word and its neighbours.\n",
    "\n",
    "e.g. \n",
    "\n",
    "\n",
    "### Information Extraction\n",
    "e.g.: “Brasilia, the Brazilian capital, was founded in 1960.\" \n",
    "-> capital(Brazil, Brasilia), founded(Brasilia, 1960)\n",
    "\n",
    "the first step is to know POS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Speech\n",
    "Open v.s. Closed classes: How readily do POS categories take on new words?\n",
    "\n",
    "### POS Open Classes (English)\n",
    "e.g. \n",
    "\n",
    "Nouns: Proper v.s. common; Mass v.s. count\n",
    "\n",
    "Verbs: Rich inflection (go/goes/going...); Auxiliary verbs (be, have, and do); Transitivity (wait v.s. hit v.s. give) AKA number of arguments;  \n",
    "\n",
    "Adjectives: gradable (happy/happier/est) v.s. non-gradable (computational)\n",
    "\n",
    "Adverbs: Manner (slowly); Locative (here); Degree (really); Temporal (today)\n",
    "\n",
    "**Noun and Verb are in most languages.**\n",
    "\n",
    "### POS Closed Classes (English)\n",
    "They won't grow in number when new words are invented.\n",
    "\n",
    "Prepositions (in, on, with, for, of...): give relationship between two entities.\n",
    "\n",
    "Particles: (brushed himself off) after the verbs\n",
    "\n",
    "Determiners: Articles (a, an, the); Demonstratives (this, that); Quantifiers (each, every, some, two)\n",
    "\n",
    "Pronouns: Personal (i, me, she); Possessive (my, our); Interrogative or Wh (who, what...)\n",
    "\n",
    "Conjunctions: Coordinating (and, or, but) to link two clauses together, equally; Subordinating (if, although, that...); Subordinating (if, although, that...) not equally\n",
    "\n",
    "Modal verbs: Ability (can, could); Permission (can, may); Possibility (may, might, could); Necessity (must)\n",
    "\n",
    "Negatives, Politeness markers, etc...\n",
    "\n",
    "### Ambiguity\n",
    "Many word types belong to multiple classes\n",
    "\n",
    "POS depends on context\n",
    "\n",
    "e.g.1: \"Time flies like an arrow\", \n",
    "\n",
    "| Time | flies | like | an | arrow | \n",
    "| noun | verb | preposition | determiner | noun | \n",
    "\n",
    "\"Fruit flies like a banana\"\n",
    "| Fruit | flies | like | a | banana |\n",
    "| noun | noun | verb | determiner | noun |\n",
    "\n",
    "e.g.2: POS Ambiguity in News Headlines\n",
    "<img src=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagsets (标签集)\n",
    "A compact of representation of POS information (<= 4 capitalized characters; includes inflectional distinctions)\n",
    "\n",
    "Major English tagsets: Brown, Penn Treebank; CLAWS/BNC; Universal (project; 12 tags)\n",
    "\n",
    "At least one tagset for all major languages\n",
    "\n",
    "### Major Penn Treebank Tags\n",
    "\n",
    "<img src=\"\">\n",
    "\n",
    "### Derived Tags (open class)\n",
    "NN (noun singular, wombat) -> NNs (plural, wombats) -> NNP (proper, Australia) -> NNPS (proper plural, Australians)\n",
    "\n",
    "VB (verb infinitive, eat) -> VBP (1st/2nd person present, eat) -> VBZ (3rd person singular, eats) -> VBD (past tense, ate) -> VBG (gerund, eating) -> VBN (past participle, eaten)\n",
    "\n",
    "JJ (adjective, nice) -> JJR (comparative, nicer) -> JJS (superlative, nicest)\n",
    "\n",
    "RB (adverb, fast) -> RBR (comparative, faster) -> RBS (superlative, fastest)\n",
    "\n",
    "### Derived Tags (closed Class)\n",
    "PRP (pronoun personal)\n",
    "\n",
    "WP (Wh-pronoun, what) -> WP$ -> WDT -> WRB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Tagging\n",
    "\n",
    "### Why Automatically POS tag?\n",
    "for morphological analysis (lemmatization); applications (information retrieval-nouns, sentiment analysis-adj); features for classification task; POS tags can offer word sense disambiguation (e.g. cross/NN vs cross/VB cross/JJ); use to create larger structures (parsing)\n",
    "\n",
    "### Automatic Taggers\n",
    "<font color=red>Rule-based taggers; Statistical taggers (Unigram, Classifier-based, Hidden Markov Model; require large corpus);</font>\n",
    "\n",
    "### Rule-based tagging\n",
    "start with a list of possible tags for each word (lexical resource/corpus)\n",
    "\n",
    "often includes other lexical information (e.g. verb subcategorisation-arguments)\n",
    "\n",
    "Apply rules to narrow down to a single tag (Relies on some unambiguous contexts)\n",
    "\n",
    "Large systems have 1000s of constraints\n",
    "\n",
    "### Unigram tagger\n",
    "Assign most common tag to each word type\n",
    "\n",
    "requires a labelled corpus (by human) of tagged words\n",
    "\n",
    "\"Model\" is just a look-up table; But actually quite good, ~90% accuracy (correctly resolves about 75# of ambiguity)\n",
    "\n",
    "Often considered the baseline for more complex approaches\n",
    "\n",
    "### Classifier-Based Tagging\n",
    "Use a standard discriminative classifier (e.g. logistic regression, neural network) with features: Target word, Lexical context around the word, Already classified tags in sentence\n",
    "\n",
    "But suffer from error propagation: wrong predictions from previous steps affect the next ones\n",
    "\n",
    "### Hidden Markov Models\n",
    "A basic sequential (or structured) model\n",
    "\n",
    "like sequential classifiers, use both previous tag and lexical evidence\n",
    "\n",
    "Unlike classifiers, considers all possibilities of previous tag; treat previous tag evidence and lexical evidence as independent from each other (less sparsity; fast algorithms for sequential prediction, e.g. finding the best tagging of entire word sequence)\n",
    "\n",
    "### Unkown Words\n",
    "Huge problem in morphologically rich languages (e.g. Turkish)\n",
    "\n",
    "1. Can use things we’ve seen only once (hapax legomena) to best guess for things we’ve never seen before (e.g. verb-noun; unlikely to be determiners)\n",
    "2. Can use sub-word representations to capture morphology (look for common affixes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8f9177a0acce8018d23d7772672ff7f2c1807cf103258a4b51e26a443b2e37b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
